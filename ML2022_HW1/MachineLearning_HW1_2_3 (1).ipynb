{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNk8bw4+V5wxWmIY6pVuzZj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Key Difference Between MLE and MAP is the regression coefficient like θ or W in this case\n","\n","For MLE, W is fixed. but in MAP W is a random variable.  \n","For MLE we don't need assumption besides prediction model. But in MAP we need \"assume\" a \"prior\" to maximize the posterior  \n","Which result in MAP being more \"subjective\".  \n","With good prior, we can fit target more well than MLE  \n",", but with bad prior, we could lead to a result far from correct answer\n","  \n","Overall, MAP can be seen as a regulized approch similar to MLE\n"],"metadata":{"id":"T7qO1JstM6jG"}},{"cell_type":"markdown","source":["**------------------------------------Initializing--------------------------------------------**"],"metadata":{"id":"Jt-sjUf8NGPP"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCRJDrTDMmpO","executionInfo":{"status":"ok","timestamp":1666009184590,"user_tz":-480,"elapsed":15841,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}},"outputId":"c9ec70c8-2df0-4da9-fdf4-ebf9554948db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","wine_data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/X.csv\")\n","wine_target=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/T.csv\")\n","\n","wine_features=[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"]\n","X=wine_data[wine_features]\n","Y=wine_target"],"metadata":{"id":"LnFZR1RONgx6","executionInfo":{"status":"ok","timestamp":1666009217308,"user_tz":-480,"elapsed":1558,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["**------------------------------------Func used in last part--------------------------------------------**"],"metadata":{"id":"ATwcAmawNi4U"}},{"cell_type":"code","source":["def split_DataFrame(X,N): #Can't handle Series\n","    df_1=X.iloc[:N,:]\n","    df_2=X.iloc[N:,:]\n","    return df_1, df_2\n","def variance_numpy(W0,W,X,Y):\n","    N,D=X.shape\n","    count=0\n","    for i in range(N):\n","        count+=(predict(W0, W, X[i])-Y[i])**2\n","    count/=N\n","    return count\n","def gaussian(x,u,var):\n","    deviation=np.sqrt(var)\n","    tmp=np.sqrt(2*np.pi)\n","    probability=np.exp(-(x-u)**2/(2*var))/(deviation*tmp)\n","    return probability\n","def predict(W0,W1,X):\n","    X=X.reshape(len(X),1)\n","    return np.matmul(W1,X)+W0\n","def regression_M(X,Y,M):\n","    X_numpy=X.to_numpy()\n","    Y_numpy=Y.to_numpy()\n","    H=X_numpy\n","    N, D=X_numpy.shape\n","    i=0\n","    for m in range(1,M):\n","        coefs=H.size/N\n","        while i<coefs :\n","            for j in range(D):\n","                tmp=H[:,i]*X_numpy[:,j]\n","                tmp=tmp.reshape(N,1)\n","                H=np.append(H,tmp,1)\n","                #print(H.shape)\n","            i+=1\n","    \n","    ones=np.array([[1]]*N)  \n","    H=np.append(H,ones,1)   #for intercept\n","    H_trans=np.transpose(H)\n","#-------Normal Eqution-----\n","    mul=np.matmul(H_trans,H)\n","    tmp=np.linalg.pinv(mul)\n","    W=np.matmul(np.matmul(tmp,H_trans),Y_numpy)\n","\n","    intercept=W[-1]\n","    W=np.delete(W,-1)\n","    H=np.delete(H,-1,1)\n","    return intercept, W, H\n","def N_set(data,cut_size):\n","  data_set=[]\n","  N,D=data.shape\n","  cur=0\n","  while cur<(N-cut_size):\n","    data_set.append(data.iloc[cur:cur+cut_size,:])\n","    cur+=cut_size\n","    \n","  data_set.append(data.iloc[cur:,:])\n","  return data_set"],"metadata":{"id":"sinCvkbUNskI","executionInfo":{"status":"ok","timestamp":1666009364073,"user_tz":-480,"elapsed":270,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**------------------------------------New Func Define--------------------------------------------**"],"metadata":{"id":"FS5wILzXNx7z"}},{"cell_type":"code","source":["def vector_phi(x,M):\n","    D=len(x)\n","    phi=np.ones(1)\n","    cur=0\n","    for i in range(M):\n","        last_len=len(phi)\n","        while cur<last_len:\n","            for j in range(D):\n","                phi=np.append(phi,phi[cur]*x[j])\n","            cur+=1\n","    phi=np.reshape(phi,(len(phi),1))\n","    return phi\n","def Matrix_S(x_in,X,a,B,M):\n","    N,D=X.shape\n","\n","    phi_in=vector_phi(x_in,M)   \n","    D_phi=len(phi_in)\n","    phi_in_t=np.transpose(phi_in)\n","    I=np.identity(D_phi)\n","    summation=np.zeros((D_phi,D_phi))\n","\n","    for i in range(N):\n","        phi=vector_phi(X[i],M)\n","        phi_t=np.transpose(phi)\n","        summation+=phi@phi_t\n","\n","    S_inv=a*I+B*summation\n","    S=np.linalg.pinv(S_inv)\n","    return S\n","def mean_MAP(x_in, X, T, a, B, M, S):\n","    N,D=X.shape\n","    phi_in=vector_phi(x_in,M)\n","    phi_in_t=np.transpose(phi_in)\n","    D_phi=len(phi_in)\n","    \n","    summation=np.zeros((D_phi,1))\n","    for i in range(N):\n","        summation+=(T[i]*vector_phi(X[i],M))\n","    \n","    mean=B*phi_in_t@S@summation # @=>matmul\n","    return mean\n","def var_MAP(x_in,B,M,S):\n","    phi_in=vector_phi(x_in,M)\n","    phi_in_t=np.transpose(phi_in)\n","    return (1/B)+phi_in_t@S@phi_in"],"metadata":{"id":"5uL8-qLeN7oC","executionInfo":{"status":"ok","timestamp":1666009404776,"user_tz":-480,"elapsed":289,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**------------------------------------Below is the code for 2.3(b)--------------------------------------------**"],"metadata":{"id":"JF5UEKmzOQVE"}},{"cell_type":"code","source":["#--------------HyperParameter--------------------#\n","a=0.001\n","#B=0.2  #use BML in below\n","#order=1 #below will be define\n","max_order=2 #not doing M=3 it cost too much time\n","#------------------------------------------------#\n","\n","X_train, X_test=split_DataFrame(X,1500)\n","Y_train, Y_test=split_DataFrame(Y,1500)\n","X_train_numpy=X_train.to_numpy()\n","Y_train_numpy=Y_train.to_numpy()\n","X_test_numpy=X_test.to_numpy()\n","Y_test_numpy=Y_test.to_numpy()\n","\n","\n","for order in range(1,max_order+1):\n","  #--------use B ML-------------#\n","  W0, W, H_train=regression_M(X_train,Y_train,order)\n","  var_reg=variance_numpy(W0, W, H_train, Y_train_numpy)\n","  B=1/var_reg\n","  #-------------------------------#\n","  log_likelihood=np.float64(0)\n","  N,D=X_test.shape\n","\n","  for i in range(N):\n","      S=Matrix_S(X_test_numpy[i],X_train_numpy,a,B,order)\n","      mean=mean_MAP(X_test_numpy[i], X_train_numpy, Y_train_numpy,a, B, order, S)\n","      var=var_MAP(X_test_numpy[i], B, order, S)\n","      p=gaussian(Y_test_numpy[i],mean,var)\n","      log_likelihood+=np.log(p)\n","  print(\"M=\",order, \"avg log_likelihood of test\",log_likelihood/N)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lIhu-fQ0OqDu","executionInfo":{"status":"ok","timestamp":1666009739389,"user_tz":-480,"elapsed":311072,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}},"outputId":"a757146d-5f1c-46e5-98fc-7719a43fa069"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["M= 1 avg log_likelihood of test [[-0.8956122]]\n","M= 2 avg log_likelihood of test [[-0.97806948]]\n"]}]},{"cell_type":"markdown","source":["Cross Validation"],"metadata":{"id":"Qn96U8WczeDC"}},{"cell_type":"code","source":["def Validation_MAP_poly(X_train,X_test,Y_train,Y_test,a,max_order,if_print=True):\n","  X_train_numpy=X_train.to_numpy()\n","  Y_train_numpy=Y_train.to_numpy()\n","  X_test_numpy=X_test.to_numpy()\n","  Y_test_numpy=Y_test.to_numpy()\n","  ret=[]\n","\n","  for order in range(1,max_order+1):\n","    #--------use B ML-------------#\n","    W0, W, H_train=regression_M(X_train,Y_train,order)\n","    var_reg=variance_numpy(W0, W, H_train, Y_train_numpy)\n","    B=1/var_reg\n","    #-------------------------------#\n","    log_likelihood=np.float64(0)\n","    N,D=X_test.shape\n","\n","    for i in range(N):\n","      S=Matrix_S(X_test_numpy[i],X_train_numpy,a,B,order)\n","      mean=mean_MAP(X_test_numpy[i], X_train_numpy, Y_train_numpy,a, B, order, S)\n","      var=var_MAP(X_test_numpy[i], B, order, S)\n","      p=gaussian(Y_test_numpy[i],mean,var)\n","      log_likelihood+=np.log(p)\n","      \n","    log_likelihood/=N  \n","    if if_print:\n","      print(\"M=\",order, \"avg log_likelihood of test\",log_likelihood)\n","    ret.append(log_likelihood)\n"," \n","  return ret"],"metadata":{"id":"J5p5APFU0xt-","executionInfo":{"status":"ok","timestamp":1666010184041,"user_tz":-480,"elapsed":255,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["cut_size=100\n","Max_poly_order=1\n","a=0 #perform well in former example\n","\n","X_sets=N_set(X,cut_size)\n","Y_sets=N_set(Y,cut_size)\n","times=len(X_sets)\n","\n","count=[np.float64(0)]*Max_poly_order\n","for t in range(times):\n","  print(\"----------------time=\",t,\"-------------------------\")\n","  X_train=pd.DataFrame()\n","  Y_train=pd.DataFrame()\n","  X_test=X_sets[t].copy()\n","  Y_test=Y_sets[t].copy()\n","  for i in range(times):\n","    if i==t :\n","      continue\n","    else:\n","      X_train=X_train.append(X_sets[i])\n","      Y_train=Y_train.append(Y_sets[i])\n","  tmp=Validation_MAP_poly(X_train, X_test, Y_train, Y_test,a, Max_poly_order)\n","  for i in range(Max_poly_order):\n","    count[i]+=tmp[i]\n","print(\"############################################\")\n","for i in range(Max_poly_order):\n","  print(\"average likelihood of M=\",i+1,\": \",count[i]/times)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3oD0950o0WBY","executionInfo":{"status":"ok","timestamp":1666010627514,"user_tz":-480,"elapsed":441395,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}},"outputId":"5d3cb332-c6a8-4647-aabe-f4013349c15d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------time= 0 -------------------------\n","M= 1 avg log_likelihood of test [[-1.06815721]]\n","----------------time= 1 -------------------------\n","M= 1 avg log_likelihood of test [[-0.87325257]]\n","----------------time= 2 -------------------------\n","M= 1 avg log_likelihood of test [[-1.02279663]]\n","----------------time= 3 -------------------------\n","M= 1 avg log_likelihood of test [[-0.98222199]]\n","----------------time= 4 -------------------------\n","M= 1 avg log_likelihood of test [[-1.15473474]]\n","----------------time= 5 -------------------------\n","M= 1 avg log_likelihood of test [[-0.95008983]]\n","----------------time= 6 -------------------------\n","M= 1 avg log_likelihood of test [[-1.00592418]]\n","----------------time= 7 -------------------------\n","M= 1 avg log_likelihood of test [[-0.86043515]]\n","----------------time= 8 -------------------------\n","M= 1 avg log_likelihood of test [[-1.10858058]]\n","----------------time= 9 -------------------------\n","M= 1 avg log_likelihood of test [[-1.00608294]]\n","----------------time= 10 -------------------------\n","M= 1 avg log_likelihood of test [[-1.03766164]]\n","----------------time= 11 -------------------------\n","M= 1 avg log_likelihood of test [[-0.86072056]]\n","----------------time= 12 -------------------------\n","M= 1 avg log_likelihood of test [[-1.11481789]]\n","----------------time= 13 -------------------------\n","M= 1 avg log_likelihood of test [[-0.83509523]]\n","----------------time= 14 -------------------------\n","M= 1 avg log_likelihood of test [[-1.23584314]]\n","----------------time= 15 -------------------------\n","M= 1 avg log_likelihood of test [[-0.89563383]]\n","############################################\n","average likelihood of M= 1 :  [[-1.00075301]]\n"]}]},{"cell_type":"markdown","source":["The result above is perform pretty similar to\"average likelihood of M= [-1.0016]\"\n","in MLE of same data set  \n","\n","So, below I try to find another hyperparameter a to achieve better performance"],"metadata":{"id":"6HIHDjCU64xl"}},{"cell_type":"markdown","source":["finding best a for M=1"],"metadata":{"id":"HibC_HD9QmaQ"}},{"cell_type":"code","source":["def cross_validation_MAP(X,Y,cut_size,Max_order,a):\n","\n","  X_sets=N_set(X,cut_size)\n","  Y_sets=N_set(Y,cut_size)\n","  times=len(X_sets)\n","\n","  count=[np.float64(0)]*Max_order\n","  for t in range(times):\n","    #print(\"----------time=\",t,\"-------------------------\")\n","    X_train=pd.DataFrame()\n","    Y_train=pd.DataFrame()\n","    X_test=X_sets[t].copy()\n","    Y_test=Y_sets[t].copy()\n","    for i in range(times):\n","      if i==t :\n","        continue\n","      else:\n","        X_train=X_train.append(X_sets[i])\n","        Y_train=Y_train.append(Y_sets[i])\n","    tmp=Validation_MAP_poly(X_train, X_test, Y_train, Y_test,a, Max_order,if_print=False)\n","    for i in range(Max_order):\n","      count[i]+=tmp[i]\n","  #print(\"############################################\")\n","  for i in range(Max_order):\n","    count[i]/=times\n","    print(\"average likelihood of M=\",i+1,\": \",count[i])\n","  return count"],"metadata":{"id":"Ls0zvd7376cP","executionInfo":{"status":"ok","timestamp":1666010696850,"user_tz":-480,"elapsed":311,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["epoch=10\n","max_order=1\n","a=0.0001\n","cut_size=100\n","\n","step=np.geomspace(0.1,1,epoch)\n","likely_max=[np.float64(-1000)]*max_order\n","\n","a_max=a\n","print(step)\n","for time_epoch in range(epoch):\n","  print(\"##---------------epoch:\",time_epoch,\"------------------##\")\n","  a=step[time_epoch]\n","  cur_likely=cross_validation_MAP(X,Y,cut_size,max_order,a)\n","  for i in range(max_order):\n","    if cur_likely[i] > likely_max[i]:\n","      print(\"!!----------------------------------------------------!!\")\n","      print(\"Update New a: \",a,\"New likelihood \",cur_likely[i])\n","      likely_max[i]=cur_likely[i]\n","      a_max=a\n","      print(\"!!----------------------------------------------------!!\")\n","    else:\n","      print(\"a: \",a,\"likelihood: \",cur_likely[i])\n","print(\"Final a: \",a_max,\"Final likelihood: \",likely_max)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gqql3JeQlBG","executionInfo":{"status":"ok","timestamp":1666014692249,"user_tz":-480,"elapsed":3966425,"user":{"displayName":"蕭登方","userId":"04110943827274540537"}},"outputId":"cbf58c22-ca27-400d-ca10-096ad3eaee8b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.1        0.12915497 0.16681005 0.21544347 0.27825594 0.35938137\n"," 0.46415888 0.59948425 0.77426368 1.        ]\n","##---------------epoch: 0 ------------------##\n","average likelihood of M= 1 :  [[-0.99935537]]\n","!!----------------------------------------------------!!\n","Update New a:  0.1 New likelihood  [[-0.99935537]]\n","!!----------------------------------------------------!!\n","##---------------epoch: 1 ------------------##\n","average likelihood of M= 1 :  [[-0.99932233]]\n","!!----------------------------------------------------!!\n","Update New a:  0.1291549665014884 New likelihood  [[-0.99932233]]\n","!!----------------------------------------------------!!\n","##---------------epoch: 2 ------------------##\n","average likelihood of M= 1 :  [[-0.9992843]]\n","!!----------------------------------------------------!!\n","Update New a:  0.16681005372000587 New likelihood  [[-0.9992843]]\n","!!----------------------------------------------------!!\n","##---------------epoch: 3 ------------------##\n","average likelihood of M= 1 :  [[-0.99924162]]\n","!!----------------------------------------------------!!\n","Update New a:  0.21544346900318834 New likelihood  [[-0.99924162]]\n","!!----------------------------------------------------!!\n","##---------------epoch: 4 ------------------##\n","average likelihood of M= 1 :  [[-0.99919584]]\n","!!----------------------------------------------------!!\n","Update New a:  0.2782559402207124 New likelihood  [[-0.99919584]]\n","!!----------------------------------------------------!!\n","##---------------epoch: 5 ------------------##\n","average likelihood of M= 1 :  [[-0.99915046]]\n","!!----------------------------------------------------!!\n","Update New a:  0.35938136638046275 New likelihood  [[-0.99915046]]\n","!!----------------------------------------------------!!\n","##---------------epoch: 6 ------------------##\n","average likelihood of M= 1 :  [[-0.99911191]]\n","!!----------------------------------------------------!!\n","Update New a:  0.46415888336127786 New likelihood  [[-0.99911191]]\n","!!----------------------------------------------------!!\n","##---------------epoch: 7 ------------------##\n","average likelihood of M= 1 :  [[-0.99909072]]\n","!!----------------------------------------------------!!\n","Update New a:  0.5994842503189409 New likelihood  [[-0.99909072]]\n","!!----------------------------------------------------!!\n","##---------------epoch: 8 ------------------##\n","average likelihood of M= 1 :  [[-0.99910265]]\n","a:  0.774263682681127 likelihood:  [[-0.99910265]]\n","##---------------epoch: 9 ------------------##\n","average likelihood of M= 1 :  [[-0.99916931]]\n","a:  1.0 likelihood:  [[-0.99916931]]\n","Final a:  0.5994842503189409 Final likelihood:  [array([[-0.99909072]])]\n"]}]},{"cell_type":"markdown","source":["So,the a in the interval(1~0.1) are perform well compared to other interval,  \n","In this coarse trial we found a=0.5995 is a good choice for hyperparameter a.  \n","Or we can get more precise result by applying other optimizing algorithm like GD."],"metadata":{"id":"jUGu3ZjeY1ET"}},{"cell_type":"markdown","source":["**-------------------------Conclusion--------------------------**"],"metadata":{"id":"63NuK5TtdziW"}},{"cell_type":"markdown","source":["The data is never enough so MLE never find the \"real\" underlying parameter,but the assumption based on data.  \n","But, MAP providing us an approach or a chance to reach the \"real\" underlying parameter beyond the scope of data  \n","By taking an appropriate prior, we can have a regulizing approach acquiring more \"reasonable\" prediction\n","  \n","Above results verify that we can adjust our prior(alpha in this case) to get higher likelihood than MLE approch.  \n","same data in MLE:average cross validation likelihood of M= 1 :  [-1.00224412]  \n","but in MAP: average cross validation likelihood of M= 1 :  [[-0.99909072]]  \n","\n","So, with goood prior we can obtain better prediction"],"metadata":{"id":"EuU7rbTXd5DY"}}]}